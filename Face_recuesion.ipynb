{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "1rJqbNEgWVjY6maIV0RoCI4nsCQ1Ebehv",
      "authorship_tag": "ABX9TyOn0/4aXyu0EZfH2B70Tx/7",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/iitdamansharma/Face-Detection/blob/main/Face_recuesion.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Adding more Model to get better classification you know **"
      ],
      "metadata": {
        "id": "rq4VEALoYMiP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install opencv-python numpy scikit-learn joblib\n",
        "import cv2, os, numpy as np\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "import joblib\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pNZfxmP0BpqD",
        "outputId": "538abea1-1e93-4fe8-ada7-2bd1c19d03b8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: opencv-python in /usr/local/lib/python3.12/dist-packages (4.12.0.88)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (2.0.2)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.12/dist-packages (1.6.1)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.12/dist-packages (1.5.2)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn) (1.16.3)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn) (3.6.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from skimage.feature import hog\n",
        "\n",
        "def extract_hog_features(img):\n",
        "    img = cv2.resize(img, (80, 80))  # standardize size\n",
        "    features, _ = hog(img,\n",
        "                      orientations=9,\n",
        "                      pixels_per_cell=(8, 8),\n",
        "                      cells_per_block=(2, 2),\n",
        "                      visualize=True,\n",
        "                      block_norm='L2-Hys')\n",
        "    return features\n"
      ],
      "metadata": {
        "id": "vtbalCvlBzCC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "DATA_DIR = \"data\"\n",
        "haar = cv2.CascadeClassifier(cv2.data.haarcascades + \"haarcascade_frontalface_default.xml\")\n",
        "\n",
        "X, y, id_map, label_map = [], [], {}, {}\n",
        "cur_id = 0\n",
        "\n",
        "for person in os.listdir(DATA_DIR):\n",
        "    person_path = os.path.join(DATA_DIR, person)\n",
        "    if not os.path.isdir(person_path): continue\n",
        "\n",
        "    id_map[cur_id] = person\n",
        "    label_map[person] = cur_id\n",
        "\n",
        "    for img_name in os.listdir(person_path):\n",
        "        path = os.path.join(person_path, img_name)\n",
        "        img = cv2.imread(path)\n",
        "        if img is None: continue\n",
        "        gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
        "        faces = haar.detectMultiScale(gray, 1.3, 5)\n",
        "\n",
        "        for (x, y1, w, h) in faces:\n",
        "            face = gray[y1:y1+h, x:x+w]\n",
        "            feat = extract_hog_features(face)\n",
        "            X.append(feat)\n",
        "            y.append(cur_id)\n",
        "    cur_id += 1\n",
        "\n",
        "X = np.array(X)\n",
        "y = np.array(y)\n",
        "print(f\"âœ… Loaded {len(X)} samples from {len(id_map)} people.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bfXLcLc4B2k8",
        "outputId": "ba3a1e03-99b3-4b1b-ce14-c7d9cc0f7a7f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "âœ… Loaded 25 samples from 4 people.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "scaler = StandardScaler()\n",
        "X_train = scaler.fit_transform(X_train)\n",
        "X_test = scaler.transform(X_test)\n",
        "\n",
        "best_acc = 0\n",
        "best_k = 1\n",
        "for k in range(1, 10):\n",
        "    if len(X_train) < k: # Skip if training set is too small for current k\n",
        "        continue\n",
        "    knn = KNeighborsClassifier(n_neighbors=k, weights='distance')\n",
        "    knn.fit(X_train, y_train)\n",
        "    acc = accuracy_score(y_test, knn.predict(X_test))\n",
        "    if acc > best_acc:\n",
        "        best_acc = acc\n",
        "        best_k = k\n",
        "print(f\"ðŸ”¥ Best K = {best_k}, Accuracy = {best_acc*100:.2f}%\")\n",
        "\n",
        "knn = KNeighborsClassifier(n_neighbors=best_k, weights='distance')\n",
        "knn.fit(X_train, y_train)\n",
        "\n",
        "os.makedirs(\"model\", exist_ok=True)\n",
        "joblib.dump((knn, scaler, id_map), \"model/face_knn.pkl\")\n",
        "print(\"âœ… Model trained and saved successfully.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9m5ei4TVCDml",
        "outputId": "abf69b7d-dab6-4669-a4e6-f415c3e199a4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ðŸ”¥ Best K = 1, Accuracy = 80.00%\n",
            "âœ… Model trained and saved successfully.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2, numpy as np, os\n",
        "from PIL import Image, ImageEnhance\n",
        "import random\n",
        "\n",
        "# Input image\n",
        "# Make sure 'face.jpg' is in the same directory as your notebook, or provide the full path.\n",
        "img = cv2.imread(\"/content/data/Himanshu/WhatsApp Image 2025-11-06 at 16.14.48_78310902.jpg\")\n",
        "os.makedirs(\"data/Himanshu\", exist_ok=True)\n",
        "\n",
        "# Check if the image was loaded successfully\n",
        "if img is None:\n",
        "    print(\"Error: Could not load the image 'face.jpg'. Please check the file path.\")\n",
        "else:\n",
        "    def augment_image(img):\n",
        "        pil_img = Image.fromarray(cv2.cvtColor(img, cv2.COLOR_BGR2RGB))\n",
        "\n",
        "        # Random brightness/contrast\n",
        "        enhancer = ImageEnhance.Brightness(pil_img)\n",
        "        pil_img = enhancer.enhance(random.uniform(0.6, 1.4))\n",
        "        enhancer = ImageEnhance.Contrast(pil_img)\n",
        "        pil_img = enhancer.enhance(random.uniform(0.7, 1.3))\n",
        "\n",
        "        # Random rotation\n",
        "        angle = random.randint(-15, 15)\n",
        "        pil_img = pil_img.rotate(angle)\n",
        "\n",
        "        # Convert back to numpy\n",
        "        img_aug = cv2.cvtColor(np.array(pil_img), cv2.COLOR_RGB2BGR)\n",
        "\n",
        "        # Random flip\n",
        "        if random.choice([True, False]):\n",
        "            img_aug = cv2.flip(img_aug, 1)\n",
        "\n",
        "        # Random noise\n",
        "        noise = np.random.randint(0, 15, img_aug.shape, dtype='uint8')\n",
        "        img_aug = cv2.add(img_aug, noise)\n",
        "\n",
        "        return img_aug\n",
        "\n",
        "    for i in range(15):\n",
        "        aug_img = augment_image(img)\n",
        "        cv2.imwrite(f\"data/Himanshu/{i}.jpg\", aug_img)\n",
        "\n",
        "    print(\"âœ… Generated 15 augmented images in Himanshu/aman/\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-tAA1BD-bpcy",
        "outputId": "921ff78e-a8ae-4d6f-b2f0-bc7d953a765a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "âœ… Generated 15 augmented images in Himanshu/aman/\n"
          ]
        }
      ]
    }
  ]
}